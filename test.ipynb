{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Iterable, Self\n",
    "from numpy.typing import NDArray\n",
    "import datasets\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import einops\n",
    "\n",
    "import flagon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist() -> datasets.Dataset:\n",
    "    \"\"\"\n",
    "    Load the Fashion MNIST dataset http://arxiv.org/abs/1708.07747\n",
    "\n",
    "    Arguments:\n",
    "    - seed: seed value for the rng used in the dataset\n",
    "    \"\"\"\n",
    "    ds = datasets.load_dataset(\"fashion_mnist\")\n",
    "    ds = ds.map(\n",
    "        lambda e: {\n",
    "            'X': einops.rearrange(np.array(e['image'], dtype=np.float32) / 255, \"h (w c) -> h w c\", c=1),\n",
    "            'Y': e['label']\n",
    "        },\n",
    "        remove_columns=['image', 'label']\n",
    "    )\n",
    "    features = ds['train'].features\n",
    "    features['X'] = datasets.Array3D(shape=(28, 28, 1), dtype='float32')\n",
    "    ds['train'] = ds['train'].cast(features)\n",
    "    ds['test'] = ds['test'].cast(features)\n",
    "    ds.set_format('numpy')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() -> tf.keras.Model:\n",
    "    inputs = tf.keras.Input((28, 28, 1))\n",
    "    x = tf.keras.layers.Flatten()(inputs)\n",
    "    x = tf.keras.layers.Dense(100, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(50, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(flagon.Client):\n",
    "    def __init__(self, data, create_model_fn):\n",
    "        self.data = data\n",
    "        self.model = create_model_fn()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        history = self.model.fit(self.data['train']['X'], self.data['train']['Y'], epochs=config['num_epochs'], steps_per_epoch=config.get(\"num_steps\"), verbose=0)\n",
    "        return self.model.get_weights(), len(self.data['train']), {k: v[-1] for k, v in history.history.items()}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, accuracy = self.model.evaluate(self.data['test']['X'], self.data['test']['Y'], verbose=0)\n",
    "        return len(self.data['test']), {'loss': loss, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(labels, nclients, rng, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Latent Dirichlet allocation defined in https://arxiv.org/abs/1909.06335\n",
    "    default value from https://arxiv.org/abs/2002.06440\n",
    "    Optional arguments:\n",
    "    - alpha: the alpha parameter of the Dirichlet function,\n",
    "    the distribution is more i.i.d. as alpha approaches infinity and less i.i.d. as alpha approaches 0\n",
    "    \"\"\"\n",
    "    distribution = [[] for _ in range(nclients)]\n",
    "    nclasses = len(np.unique(labels))\n",
    "    proportions = rng.dirichlet(np.repeat(alpha, nclients), size=nclasses)\n",
    "    for c in range(nclasses):\n",
    "        idx_c = np.where(labels == c)[0]\n",
    "        rng.shuffle(idx_c)\n",
    "        dists_c = np.split(idx_c, np.round(np.cumsum(proportions[c]) * len(idx_c)).astype(int)[:-1])\n",
    "        distribution = [distribution[i] + d.tolist() for i, d in enumerate(dists_c)]\n",
    "    return distribution\n",
    "\n",
    "def create_clients(data, create_model_fn, network_arch, seed=None):\n",
    "    Y = data['train']['Y']\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = iter(lda(Y, flagon.common.count_clients(network_arch), rng, alpha=1000))\n",
    "\n",
    "    def create_client(client_id: str) -> Client:\n",
    "        return Client(datasets.DatasetDict(train=data['train'].select(next(idx)), test=data['test']), create_model_fn)\n",
    "    return create_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/home/cody/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48)\n",
      "100%|██████████| 2/2 [00:00<00:00, 871.54it/s]\n",
      "Loading cached processed dataset at /home/cody/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48/cache-e93fd02beb204798.arrow\n",
      "Loading cached processed dataset at /home/cody/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48/cache-d78c8302bd9de403.arrow\n",
      "Loading cached processed dataset at /home/cody/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48/cache-31c809cd0ba5b588.arrow\n",
      "Loading cached processed dataset at /home/cody/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48/cache-3b739fab5d538e16.arrow\n",
      "| flagon INFO @ 2023-07-12 09:22:09,441 in server.py:54 | Registering 10 clients to the server\n",
      "| flagon INFO @ 2023-07-12 09:22:09,442 in server.py:64 | Starting training on the server for 5 rounds\n",
      "| flagon INFO @ 2023-07-12 09:22:17,615 in server.py:83 | Aggregated training metrics at round 1: {'loss': 0.8116541919449966, 'accuracy': 0.7053000059187412}\n",
      "| flagon INFO @ 2023-07-12 09:22:17,616 in server.py:84 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 09:22:17,616 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 09:22:19,529 in server.py:112 | Completed server analytics in 1.9129927158355713s\n",
      "| flagon INFO @ 2023-07-12 09:22:19,530 in server.py:114 | Aggregated final metrics {'loss': 1.3540154695510864, 'accuracy': 0.5952000021934509}\n",
      "| flagon INFO @ 2023-07-12 09:22:24,427 in server.py:83 | Aggregated training metrics at round 2: {'loss': 0.6804275287558635, 'accuracy': 0.7550500003596147}\n",
      "| flagon INFO @ 2023-07-12 09:22:24,427 in server.py:84 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 09:22:24,427 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 09:22:25,886 in server.py:112 | Completed server analytics in 1.4576876163482666s\n",
      "| flagon INFO @ 2023-07-12 09:22:25,886 in server.py:114 | Aggregated final metrics {'loss': 0.5699861645698547, 'accuracy': 0.785099983215332}\n",
      "| flagon INFO @ 2023-07-12 09:22:30,822 in server.py:83 | Aggregated training metrics at round 3: {'loss': 0.5713868919998407, 'accuracy': 0.7898999921401342}\n",
      "| flagon INFO @ 2023-07-12 09:22:30,822 in server.py:84 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 09:22:30,822 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 09:22:32,284 in server.py:112 | Completed server analytics in 1.46108078956604s\n",
      "| flagon INFO @ 2023-07-12 09:22:32,284 in server.py:114 | Aggregated final metrics {'loss': 0.5123581290245056, 'accuracy': 0.8070999979972839}\n",
      "| flagon INFO @ 2023-07-12 09:22:37,026 in server.py:83 | Aggregated training metrics at round 4: {'loss': 0.5321082727054754, 'accuracy': 0.8038333238353332}\n",
      "| flagon INFO @ 2023-07-12 09:22:37,027 in server.py:84 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 09:22:37,027 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 09:22:38,491 in server.py:112 | Completed server analytics in 1.4637038707733154s\n",
      "| flagon INFO @ 2023-07-12 09:22:38,491 in server.py:114 | Aggregated final metrics {'loss': 0.49462032318115234, 'accuracy': 0.8166999816894531}\n",
      "| flagon INFO @ 2023-07-12 09:22:43,291 in server.py:83 | Aggregated training metrics at round 5: {'loss': 0.5100321194693446, 'accuracy': 0.8111166528304418}\n",
      "| flagon INFO @ 2023-07-12 09:22:43,291 in server.py:84 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 09:22:43,291 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 09:22:44,752 in server.py:112 | Completed server analytics in 1.4602811336517334s\n",
      "| flagon INFO @ 2023-07-12 09:22:44,752 in server.py:114 | Aggregated final metrics {'loss': 0.47877031564712524, 'accuracy': 0.8209999799728394}\n",
      "| flagon INFO @ 2023-07-12 09:22:44,753 in server.py:88 | Completed server training in 35.310651779174805s\n",
      "| flagon INFO @ 2023-07-12 09:22:44,753 in server.py:89 | Distributed metrics: {1: [{'loss': 0.8350491523742676, 'accuracy': 0.6943439841270447}, {'loss': 0.8045979738235474, 'accuracy': 0.7110628485679626}, {'loss': 0.8199605941772461, 'accuracy': 0.7059319019317627}, {'loss': 0.8108550906181335, 'accuracy': 0.7025589942932129}, {'loss': 0.8364015221595764, 'accuracy': 0.6932515501976013}, {'loss': 0.7949504852294922, 'accuracy': 0.7211743593215942}, {'loss': 0.8258612155914307, 'accuracy': 0.6921924352645874}, {'loss': 0.7991764545440674, 'accuracy': 0.708164632320404}, {'loss': 0.7839167714118958, 'accuracy': 0.7242665886878967}, {'loss': 0.8050518035888672, 'accuracy': 0.700431764125824}], 2: [{'loss': 0.7213869094848633, 'accuracy': 0.7402170300483704}, {'loss': 0.6780139207839966, 'accuracy': 0.7548462748527527}, {'loss': 0.6615207195281982, 'accuracy': 0.7620491981506348}, {'loss': 0.6649852395057678, 'accuracy': 0.7532402873039246}, {'loss': 0.6975248456001282, 'accuracy': 0.7492952942848206}, {'loss': 0.6613792777061462, 'accuracy': 0.767426609992981}, {'loss': 0.6950070261955261, 'accuracy': 0.744631290435791}, {'loss': 0.6836308836936951, 'accuracy': 0.7535424828529358}, {'loss': 0.6759791374206543, 'accuracy': 0.7614040970802307}, {'loss': 0.6643431186676025, 'accuracy': 0.7640318870544434}], 3: [{'loss': 0.5990594029426575, 'accuracy': 0.7772114276885986}, {'loss': 0.5609865784645081, 'accuracy': 0.7967914342880249}, {'loss': 0.5714900493621826, 'accuracy': 0.7938995361328125}, {'loss': 0.5659778118133545, 'accuracy': 0.7927883267402649}, {'loss': 0.5945388674736023, 'accuracy': 0.7807992100715637}, {'loss': 0.5541812181472778, 'accuracy': 0.7977693676948547}, {'loss': 0.5625741481781006, 'accuracy': 0.7884135246276855}, {'loss': 0.5664427280426025, 'accuracy': 0.7879554629325867}, {'loss': 0.5608575344085693, 'accuracy': 0.7980328798294067}, {'loss': 0.5772791504859924, 'accuracy': 0.7856193780899048}], 4: [{'loss': 0.5568750500679016, 'accuracy': 0.7956264615058899}, {'loss': 0.5334581732749939, 'accuracy': 0.8044785857200623}, {'loss': 0.5219637155532837, 'accuracy': 0.8056960105895996}, {'loss': 0.5287637710571289, 'accuracy': 0.8074110746383667}, {'loss': 0.5491873025894165, 'accuracy': 0.7998673319816589}, {'loss': 0.5101671814918518, 'accuracy': 0.8146629333496094}, {'loss': 0.5467739105224609, 'accuracy': 0.7869152426719666}, {'loss': 0.5231306552886963, 'accuracy': 0.8058366775512695}, {'loss': 0.5210445523262024, 'accuracy': 0.8134644627571106}, {'loss': 0.5292441844940186, 'accuracy': 0.8045499920845032}], 5: [{'loss': 0.5256440043449402, 'accuracy': 0.806313693523407}, {'loss': 0.49727994203567505, 'accuracy': 0.8175133466720581}, {'loss': 0.5084021091461182, 'accuracy': 0.8122682571411133}, {'loss': 0.5126890540122986, 'accuracy': 0.8125622868537903}, {'loss': 0.5257354974746704, 'accuracy': 0.8053390979766846}, {'loss': 0.4905228912830353, 'accuracy': 0.818599283695221}, {'loss': 0.5203786492347717, 'accuracy': 0.7970700860023499}, {'loss': 0.4993627667427063, 'accuracy': 0.8135964870452881}, {'loss': 0.501018226146698, 'accuracy': 0.8171951770782471}, {'loss': 0.5189216136932373, 'accuracy': 0.8108601570129395}]}\n",
      "| flagon INFO @ 2023-07-12 09:22:44,753 in server.py:94 | Aggregated final metrics {'loss': 0.5100321194693446, 'accuracy': 0.8111166528304418}\n",
      "| flagon INFO @ 2023-07-12 09:22:44,753 in server.py:95 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 09:22:44,754 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 09:22:46,180 in server.py:112 | Completed server analytics in 1.4258763790130615s\n",
      "| flagon INFO @ 2023-07-12 09:22:46,180 in server.py:114 | Aggregated final metrics {'loss': 0.47877031564712524, 'accuracy': 0.8209999799728394}\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "server = flagon.Server(create_model().get_weights(), {\"num_rounds\": 5, \"num_epochs\": 1, \"eval_every\": 1})\n",
    "network_arch = {\"clients\": 10}\n",
    "history = flagon.start_simulation(\n",
    "    server,\n",
    "    create_clients(load_mnist(), create_model, network_arch, seed=42),\n",
    "    network_arch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataDict:\n",
    "    def __init__(self, data: Dict[str, NDArray]):\n",
    "        self.__data = data\n",
    "        length = 0\n",
    "        for k, v in data.items():\n",
    "            if length == 0:\n",
    "                length = len(v)\n",
    "            elif length != len(v):\n",
    "                raise AttributeError(f\"Data should be composed of equal length arrays, column {k} has length {len(v)} should be {length}\")\n",
    "        self.length = length\n",
    "\n",
    "    def select(self, idx: int | Iterable[int | bool]):\n",
    "        return DataDict({k: v[idx] for k, v in self.__data.items()})\n",
    "\n",
    "    def map(self, mapping_fn: Callable[[Dict[str, NDArray]], Dict[str, NDArray]]) -> Self:\n",
    "        self.__data = mapping_fn(self.__data)\n",
    "        return self\n",
    "\n",
    "    def __getitem__(self, i: str) -> NDArray:\n",
    "        return self.__data[i]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.__data['X'])\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return str(self.__data)\n",
    "    \n",
    "    def short_details(self) -> str:\n",
    "        details = \"{\"\n",
    "        for k, v in self.__data.items():\n",
    "            details += f\"{k}: type {v.dtype}, shape {v.shape}, range [{v.min()}, {v.max()}], \"\n",
    "        details = details[:-2] + \"}\"\n",
    "        return details\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, data: Dict[str, Dict[str, NDArray]]):\n",
    "        self.__data = {k: DataDict(v) for k, v in data.items()}\n",
    "    \n",
    "    def __getitem__(self, i: str) -> DataDict:\n",
    "        return self.__data[i]\n",
    "    \n",
    "    def map(self, mapping_fn: Callable[[Dict[str, NDArray]], Dict[str, NDArray]]) -> Self:\n",
    "        for v in self.__data.values():\n",
    "            v.map(mapping_fn)\n",
    "        return self\n",
    "    \n",
    "    def keys(self) -> Iterable[str]:\n",
    "        return self.__data.keys()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        string = \"{\\n\"\n",
    "        for k, v in self.__data.items():\n",
    "            string += f\"\\t{k}: {v.short_details()}\\n\"\n",
    "        string += \"}\"\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/home/cody/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48)\n",
      "100%|██████████| 2/2 [00:00<00:00, 1135.13it/s]\n",
      "Loading cached processed dataset at /home/cody/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48/cache-e93fd02beb204798.arrow\n",
      "Loading cached processed dataset at /home/cody/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48/cache-d78c8302bd9de403.arrow\n",
      "Loading cached processed dataset at /home/cody/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48/cache-31c809cd0ba5b588.arrow\n",
      "Loading cached processed dataset at /home/cody/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48/cache-3b739fab5d538e16.arrow\n"
     ]
    }
   ],
   "source": [
    "data = load_mnist()\n",
    "data = {t: {'X': data[t]['X'], 'Y': data[t]['Y']} for t in ['train', 'test']}\n",
    "data = Data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\ttrain: {X: type float32, shape (60000, 28, 28, 1), range [0.0, 1.0], attacked X: type float64, shape (60000, 28, 28, 1), range [0.0, 1.0], Y: type int64, shape (60000,), range [0, 9]}\n",
      "\ttest: {X: type float32, shape (10000, 28, 28, 1), range [0.0, 1.0], attacked X: type float64, shape (10000, 28, 28, 1), range [0.0, 1.0], Y: type int64, shape (10000,), range [0, 9]}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "trigger_X = np.zeros((28, 28, 1))\n",
    "trigger_X[:5, :5] = 1\n",
    "data.map(lambda e: {'X': e['X'], 'attacked X': np.minimum(e['X'] + trigger_X, 1.0), 'Y': e['Y']})\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| flagon INFO @ 2023-07-12 11:09:46,009 in server.py:54 | Registering 10 clients to the server\n",
      "| flagon INFO @ 2023-07-12 11:09:46,009 in server.py:64 | Starting training on the server for 5 rounds\n",
      "| flagon INFO @ 2023-07-12 11:09:49,945 in server.py:83 | Aggregated training metrics at round 1: {'loss': 0.8344945247262716, 'accuracy': 0.6963999981274207}\n",
      "| flagon INFO @ 2023-07-12 11:09:49,946 in server.py:84 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 11:09:49,946 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 11:09:51,966 in server.py:112 | Completed server analytics in 2.019432783126831s\n",
      "| flagon INFO @ 2023-07-12 11:09:51,966 in server.py:114 | Aggregated final metrics {'loss': 1.3312294483184814, 'accuracy': 0.5892000198364258}\n",
      "| flagon INFO @ 2023-07-12 11:09:53,429 in server.py:83 | Aggregated training metrics at round 2: {'loss': 0.6982301035801569, 'accuracy': 0.7426499946465095}\n",
      "| flagon INFO @ 2023-07-12 11:09:53,430 in server.py:84 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 11:09:53,430 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 11:09:54,762 in server.py:112 | Completed server analytics in 1.332334041595459s\n",
      "| flagon INFO @ 2023-07-12 11:09:54,763 in server.py:114 | Aggregated final metrics {'loss': 0.588274359703064, 'accuracy': 0.7799000144004822}\n",
      "| flagon INFO @ 2023-07-12 11:09:56,235 in server.py:83 | Aggregated training metrics at round 3: {'loss': 0.5728450395564239, 'accuracy': 0.7899166640937328}\n",
      "| flagon INFO @ 2023-07-12 11:09:56,235 in server.py:84 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 11:09:56,236 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 11:09:57,549 in server.py:112 | Completed server analytics in 1.3131215572357178s\n",
      "| flagon INFO @ 2023-07-12 11:09:57,550 in server.py:114 | Aggregated final metrics {'loss': 0.5111759305000305, 'accuracy': 0.814300000667572}\n",
      "| flagon INFO @ 2023-07-12 11:09:58,997 in server.py:83 | Aggregated training metrics at round 4: {'loss': 0.5298659394969543, 'accuracy': 0.8077499946693579}\n",
      "| flagon INFO @ 2023-07-12 11:09:58,997 in server.py:84 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 11:09:58,998 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 11:10:00,318 in server.py:112 | Completed server analytics in 1.3206813335418701s\n",
      "| flagon INFO @ 2023-07-12 11:10:00,319 in server.py:114 | Aggregated final metrics {'loss': 0.48467719554901123, 'accuracy': 0.8212000131607056}\n",
      "| flagon INFO @ 2023-07-12 11:10:01,765 in server.py:83 | Aggregated training metrics at round 5: {'loss': 0.5047594266419609, 'accuracy': 0.8169000057985385}\n",
      "| flagon INFO @ 2023-07-12 11:10:01,766 in server.py:84 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 11:10:01,766 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 11:10:03,098 in server.py:112 | Completed server analytics in 1.3321263790130615s\n",
      "| flagon INFO @ 2023-07-12 11:10:03,099 in server.py:114 | Aggregated final metrics {'loss': 0.45506489276885986, 'accuracy': 0.8342000246047974}\n",
      "| flagon INFO @ 2023-07-12 11:10:03,099 in server.py:88 | Completed server training in 17.089643239974976s\n",
      "| flagon INFO @ 2023-07-12 11:10:03,099 in server.py:89 | Distributed metrics: {1: [{'loss': 0.8553274273872375, 'accuracy': 0.6820124983787537}, {'loss': 0.8461286425590515, 'accuracy': 0.7008689641952515}, {'loss': 0.8318870663642883, 'accuracy': 0.7005392909049988}, {'loss': 0.8024789690971375, 'accuracy': 0.7018943428993225}, {'loss': 0.9014967083930969, 'accuracy': 0.6579340100288391}, {'loss': 0.8104191422462463, 'accuracy': 0.7069050073623657}, {'loss': 0.8487551212310791, 'accuracy': 0.6893624067306519}, {'loss': 0.8209357261657715, 'accuracy': 0.6997300982475281}, {'loss': 0.8145955204963684, 'accuracy': 0.7179921865463257}, {'loss': 0.8123379349708557, 'accuracy': 0.7074061632156372}], 2: [{'loss': 0.7367990016937256, 'accuracy': 0.7255836725234985}, {'loss': 0.6838618516921997, 'accuracy': 0.7521724700927734}, {'loss': 0.6773534417152405, 'accuracy': 0.7492416501045227}, {'loss': 0.7036328315734863, 'accuracy': 0.7364572882652283}, {'loss': 0.7194981575012207, 'accuracy': 0.7330459356307983}, {'loss': 0.6951680183410645, 'accuracy': 0.74872887134552}, {'loss': 0.6991041898727417, 'accuracy': 0.7329781651496887}, {'loss': 0.6913255453109741, 'accuracy': 0.7486504912376404}, {'loss': 0.6759867668151855, 'accuracy': 0.7563167810440063}, {'loss': 0.6982338428497314, 'accuracy': 0.7439388632774353}], 3: [{'loss': 0.6003150343894958, 'accuracy': 0.772607684135437}, {'loss': 0.564624547958374, 'accuracy': 0.794451892375946}, {'loss': 0.5536185503005981, 'accuracy': 0.7952477335929871}, {'loss': 0.5845356583595276, 'accuracy': 0.7891325950622559}, {'loss': 0.6005390286445618, 'accuracy': 0.7773171663284302}, {'loss': 0.559052050113678, 'accuracy': 0.7976053953170776}, {'loss': 0.5650407075881958, 'accuracy': 0.7904111742973328}, {'loss': 0.5633192658424377, 'accuracy': 0.8012820482254028}, {'loss': 0.5582493543624878, 'accuracy': 0.7961675524711609}, {'loss': 0.5782167315483093, 'accuracy': 0.7854533195495605}], 4: [{'loss': 0.564032256603241, 'accuracy': 0.7918447852134705}, {'loss': 0.5306122899055481, 'accuracy': 0.8088235259056091}, {'loss': 0.516390860080719, 'accuracy': 0.8183349967002869}, {'loss': 0.5221250653266907, 'accuracy': 0.8110668063163757}, {'loss': 0.5580235123634338, 'accuracy': 0.8016912341117859}, {'loss': 0.5085515975952148, 'accuracy': 0.8144989609718323}, {'loss': 0.5345330238342285, 'accuracy': 0.7997336387634277}, {'loss': 0.5142298340797424, 'accuracy': 0.8159581422805786}, {'loss': 0.5223371982574463, 'accuracy': 0.8100728988647461}, {'loss': 0.5271206498146057, 'accuracy': 0.8058784604072571}], 5: [{'loss': 0.5373494029045105, 'accuracy': 0.8026964664459229}, {'loss': 0.48826324939727783, 'accuracy': 0.8235294222831726}, {'loss': 0.484500527381897, 'accuracy': 0.8287832736968994}, {'loss': 0.5003945231437683, 'accuracy': 0.8240278959274292}, {'loss': 0.5320290327072144, 'accuracy': 0.8041784167289734}, {'loss': 0.4839363396167755, 'accuracy': 0.8258159756660461}, {'loss': 0.5044028162956238, 'accuracy': 0.8162144422531128}, {'loss': 0.5000497698783875, 'accuracy': 0.813090443611145}, {'loss': 0.5154898762702942, 'accuracy': 0.8114295601844788}, {'loss': 0.5008178949356079, 'accuracy': 0.8193291425704956}]}\n",
      "| flagon INFO @ 2023-07-12 11:10:03,100 in server.py:94 | Aggregated final metrics {'loss': 0.5047594266419609, 'accuracy': 0.8169000057985385}\n",
      "| flagon INFO @ 2023-07-12 11:10:03,100 in server.py:95 | Finding test metrics\n",
      "| flagon INFO @ 2023-07-12 11:10:03,100 in server.py:103 | Performing analytics on the server\n",
      "| flagon INFO @ 2023-07-12 11:10:04,453 in server.py:112 | Completed server analytics in 1.3530633449554443s\n",
      "| flagon INFO @ 2023-07-12 11:10:04,454 in server.py:114 | Aggregated final metrics {'loss': 0.45506489276885986, 'accuracy': 0.8342000246047974}\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "server = flagon.Server(create_model().get_weights(), {\"num_rounds\": 5, \"num_epochs\": 1, \"eval_every\": 1})\n",
    "network_arch = {\"clients\": 10}\n",
    "history = flagon.start_simulation(\n",
    "    server,\n",
    "    create_clients(data, create_model, network_arch, seed=42),\n",
    "    network_arch\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
